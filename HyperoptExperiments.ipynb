{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# hyperparameter optimization routines\n",
    "from hyperopt import hp\n",
    "from hyperopt import tpe\n",
    "from hyperopt import fmin\n",
    "from hyperopt import Trials\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "# persistence images routines\n",
    "import PersistenceImages.persistence_images as pimgs\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os.path\n",
    "\n",
    "from HyperoptUtils import *\n",
    "from BoneData import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistence Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------\n",
    "# Perform a Bayesian optimization search across persistence images\n",
    "bone_df = get_bone_data_df()\n",
    "dgm_df = bone_df[['dgm']]\n",
    "target_df = bone_df['trabnum']\n",
    "scorer = make_scorer(mean_squared_error)\n",
    "max_evals = 495\n",
    "cv=6\n",
    "\n",
    "# precompute the persistence image region over the full dataset\n",
    "birth_range = (0, 0.5)\n",
    "pers_range = (0, 0.61)\n",
    "max_death = 0.7\n",
    "\n",
    "pipeline_ridge = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "\n",
    "param_space = {'estimator_params': \n",
    "                {\n",
    "                'method': pipeline_ridge,\n",
    "                'kwargs':  {\n",
    "                            'ridge__normalize':False,\n",
    "                            'ridge__fit_intercept':True,\n",
    "                            'ridge__alpha':hp.loguniform('alphas', -10, 0)\n",
    "                            }\n",
    "                },\n",
    "                'dgm_vec_params':\n",
    "                {\n",
    "                'method': vec_dgm_by_per_images,\n",
    "                'kwargs': {\n",
    "                            'birth_range': birth_range,\n",
    "                            'pers_range': pers_range,\n",
    "                            'max_death': max_death,\n",
    "                            'pixel_size': hp.uniform('pixel_size', 0.01, 0.1),\n",
    "                            'weight_params': {'n': hp.uniform('n', 1, 3)},\n",
    "                            'kernel_params': {'sigma': hp.uniform('sigma', 0.005, 0.1)},\n",
    "                            'do_plot': False\n",
    "                            }\n",
    "                }\n",
    "            }\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# create the objective function to minimize, passing in all fixed arguments\n",
    "objective = lambda params: cv_objective(params,\n",
    "                                        dgm_df=dgm_df,\n",
    "                                        target_df=target_df, \n",
    "                                        scorer=scorer,\n",
    "                                        cv=cv,\n",
    "                                        verbose=True)\n",
    "\n",
    "\n",
    "# continue parameterization run if already started\n",
    "if os.path.isfile('data/complex_vec_dgm_bayes_trials.pickle'):\n",
    "    with open('data/complex_vec_dgm_bayes_trials.pickle','rb') as f:\n",
    "        bayes_trials = pickle.load(f)\n",
    "else:\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "# run the hyperparamter optimization\n",
    "best = fmin(fn=objective, \n",
    "            space=param_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=max_evals, \n",
    "            trials=bayes_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grabbing And Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_df = get_bone_data_df()\n",
    "dgm_df = bone_df[['dgm']]\n",
    "target_df = bone_df['trabnum']\n",
    "scorer = make_scorer(mean_squared_error)\n",
    "max_evals = 495\n",
    "cv=5\n",
    "\n",
    "# precompute the persistence image region over the full dataset\n",
    "birth_range = (0, 1)\n",
    "pers_range = (0, 1)\n",
    "\n",
    "pipeline_ridge = Pipeline([('scaler', StandardScaler()), ('ridge', Ridge())])\n",
    "\n",
    "param_space = {'estimator_params': \n",
    "                {\n",
    "                'method': pipeline_ridge,\n",
    "                'kwargs':  {\n",
    "                            'ridge__normalize':False,\n",
    "                            'ridge__fit_intercept':True,\n",
    "                            'ridge__alpha':hp.loguniform('alphas', -10, 0)\n",
    "                            }\n",
    "                },\n",
    "                'dgm_vec_params':\n",
    "                {\n",
    "                'method': vec_dgm_by_per,\n",
    "                'kwargs': {\n",
    "                             'start': hp.quniform('start', 0, 150, 1),\n",
    "                             'num_pairs': hp.quniform('num_pairs', 1, 150, 1), \n",
    "                             'per_only': hp.choice('per_only', [True, False])\n",
    "                            }\n",
    "                }\n",
    "            }\n",
    "\n",
    "\n",
    "# ---------------------------------\n",
    "# create the objective function to minimize, passing in all fixed arguments\n",
    "objective = lambda params: cv_objective(params,\n",
    "                                        dgm_df=dgm_df,\n",
    "                                        target_df=target_df, \n",
    "                                        scorer=scorer,\n",
    "                                        cv=cv,\n",
    "                                        verbose=True)\n",
    "\n",
    "\n",
    "# continue parameterization run if already started\n",
    "if os.path.isfile('data/complex_vec_dgm_bayes_trials.pickle'):\n",
    "    with open('data/complex_vec_dgm_bayes_trials.pickle','rb') as f:\n",
    "        bayes_trials = pickle.load(f)\n",
    "else:\n",
    "    bayes_trials = Trials()\n",
    "\n",
    "# run the hyperparamter optimization\n",
    "best = fmin(fn=objective, \n",
    "            space=param_space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=max_evals, \n",
    "            trials=bayes_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
